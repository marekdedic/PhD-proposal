\chapter{Conclusion}
\label{chap:conclusion}

In this proposal, we have presented approaches to using graph machine learning for applications and problems inspired by the cybersecurity domain. We focused on the applicability of different models to very large graphs and hypergraphs. Here, we summarize our contributions to the considered research area and the future directions of our research.

Our first contribution was the formalization of the performance-complexity trade-off problem in machine learning on very large graphs. The formalization allows for a range of solutions to the problems and allows for a choice of a working point optimal for the application at hand. Subsequently, we presented two methods that utilize this trade-off paradigm. The fist of these methods builds on the HARP algorithm for pretraining graph machine learning models and allows for a significant reduction in graph size while keeping most of the performance. A second, direct approach to graph coarsening using a simpler, direct procedure was also presented. While the results of this method aren't as consistent, its simplicity allows for a significantly higher resolution in describing the trade-off curve. We also developed CSP, a simple and scalable algorithm for signal propagation on hypergraphs. This algorithm mainly excels in its ease of implementation and parameter-free nature. While it doesn't surpass state-of-the-art algorithms, it serves as a competitive baseline and is several orders of magnitude faster to execute. Finally, we presented the results of our study of the effect of graph properties on the performance of downstream tasks. We introduced a meta-model approach to evaluating the suitability of a graph dataset for usage with graph neural networks that allows the user to easily prototype solutions to the problem of converting a dataset into a graph.

Apart of studying the effect of graph properties on model performance, we also carried out a auxiliary study of the interplay between graph properties, model hyperparameters and model performance. This study yielded very promising results, yet wasn't sufficiently thorough to definitely verify their other aspects such as the generalization to other models and tasks. To this end, we are working on a larger study targeting solely this effect. Finally, our main direction of future research aims at the problem of explainability in graph neural networks, where the experience from previous research endeavours is combined to solve problems such as the large sizes of the datasets, explainability of hypergraphs and multi-modal graphs.
