\begin{thanks}
	I would like to express my deepest gratitude to my supervisors, Martin Holeňa and Lukáš Bajer, for their invaluable guidance, support, and encouragement throughout my PhD journey so far. Their insightful feedback and unwavering belief in my abilities have been instrumental in the completion of this thesis proposal.
\end{thanks}

\begin{declaration}
	I hereby declare that this thesis represents my own work, and all sources have been properly referenced.

	Large language models were employed for proofreading, drafting, and clarifying the text; however, they were not used for generating original research content. The author always validated and takes full responsibility for the final result.

	In Prague, \ctufield{day}\textsuperscript{th}~\monthinlanguage{title}~\ctufield{year}
\end{declaration}

\begin{abstract-english}
	Graph Neural Networks (GNNs) have become essential tools for processing graph-structured data, excelling in tasks such as node classification, link prediction, and graph classification. Their ability to utilize both node features and graph topology has driven their success across various domains. However, the application of GNNs in sensitive areas like cybersecurity is often limited by a lack of interpretability. As GNNs become increasingly utilized in these fields, there is a pressing need for explainable models that can provide insights into their decision-making processes.

	This proposal addresses several key aspects of graph machine learning, focusing on the performance and complexity trade-offs when applying GNNs to very large graphs, the impact of graph structural properties on model performance, and the development of explainable GNN models. We propose three novel approaches for optimizing this trade-off in large-scale applications. Our work also introduces a meta-model approach for evaluating graph datasets, enabling more informed decisions about graph construction and modification for optimal model performance. Furthermore, this thesis explores the intersection of graph properties, model hyperparameters, and their effects on GNN performance, setting the stage for future research into hyperparameter optimization and explainability in graph neural networks.
\end{abstract-english}

\begin{abstract-czech}
	Grafové neuronové sítě (GNN) se staly nezbytnými nástroji pro zpracování dat ve formě grafů a vynikají v úlohách, jako je klasifikace uzlů, predikce hran a klasifikace grafů. Jejich schopnost využívat jak vlastnosti uzlů, tak i topologii grafu je klíčová pro jejich úspěch napříč různými oblastmi. Aplikace GNN v citlivých oblastech, jako je kybernetická bezpečnost, však často naráží na omezení způsobená nedostatečnou interpretovatelností. S rostoucím využitím GNN v těchto oblastech roste i potřeba vysvětlitelných modelů, které mohou poskytnout vhled do svých rozhodovacích procesů.

	Tato studie se zabývá několika klíčovými aspekty strojového učení na grafech, se zaměřením na kompromisy mezi výkonem a složitostí při aplikaci GNN na velmi velké grafy, vliv strukturálních vlastností grafu na výkon modelu a vývoj vysvětlitelných GNN modelů. Navrhujeme tři nové přístupy k optimalizaci tohoto problému v aplikacích na velkých datasetech. Naše práce také představuje meta-modelový přístup k studii grafových datsasetů, což umožňuje činit lépe informovaná rozhodnutí o konstrukci a úpravách grafů pro optimální výkon modelu. Kromě toho se tato práce zabývá vzájemnými vztahy vlastností grafu, hyperparametrů modelu a jejich vlivem na výkon GNN, čímž vytváří podklad pro budoucí výzkum v oblasti optimalizace hyperparametrů a interpretovatelnosti v grafových neuronových sítích.
\end{abstract-czech}
